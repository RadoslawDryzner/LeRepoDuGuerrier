{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')"
=======
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
>>>>>>> master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import everything we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define some helpful functions that will help us during the parsing of the data.\n",
    "- get_files: returns all the .csv files for a given country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_files(country):\n",
    "    path = DATA_FOLDER + \"/ebola/\" + country + \"_data/\"\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sum_row: for a given row, returns the total value for the new cases / deaths. We first defined this function as the sum of all new cases / deaths in all provinces, but we discovered some strange data for some provinces, so we decided to only take into account the 'total' column\n",
    "- sum_rows: sum all the rows given in argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_row(row, total_col):\n",
    "    return float(row[total_col].values[0])\n",
    "\n",
    "def sum_rows(rows, total_col):\n",
    "    tot = 0\n",
    "    for row in rows:\n",
    "        tot += sum_row(row, total_col)\n",
    "    return tot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define for each country a function, which, for a given file, returns a dictionnary with the country, date, upper and lower bounds for the new cases, and upper and lower bounds for the new deaths.\n",
    "As we don't know if the new cases / deaths for the 'probable' and 'suspected' cases is reliable, we decided to create an upper bound with the sum of the 'confirmed', 'probable' and 'suspected' new cases / deaths, and a lower bound with only the 'confirmed' new cases / deaths.\n",
    "\n",
    "The structure of these functions are the same for each country, only the name of the descrption of the data changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_row_guinea(file):\n",
    "    country = 'guinea'\n",
    "    date = file[:10]\n",
    "    raw = pd.read_csv(DATA_FOLDER + \"/ebola/\" + country + \"_data/\" + file)\n",
    "    total_col = \"Totals\"\n",
    "    \n",
    "    new_cases_lower = sum_row(raw[raw.Description == \"New cases of confirmed\"], total_col)\n",
    "    new_cases_upper = sum_row(raw[raw.Description == \"Total new cases registered so far\"], total_col)\n",
    "        \n",
    "    new_deaths_lower = sum_row(raw[(raw.Description == \"New deaths registered today (confirmed)\") | (raw.Description == \"New deaths registered\")], total_col)\n",
    "    new_deaths_upper = sum_row(raw[(raw.Description == \"New deaths registered today\") | (raw.Description == \"New deaths registered\")], total_col)\n",
    "    \n",
    "    return {'Country' : country, 'Date' : parse(date), 'NewCasesLower' : new_cases_lower, 'NewCasesUpper' : new_cases_upper, 'NewDeathsLower' : new_deaths_lower, 'NewDeathsUpper' : new_deaths_upper}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_row_liberia(file):\n",
    "    country = 'liberia'\n",
    "    date = file[:10]\n",
    "    raw = pd.read_csv(DATA_FOLDER + \"/ebola/\" + country + \"_data/\" + file).fillna(0)\n",
    "    total_col = \"National\"\n",
    "    \n",
    "    new_cases_lower = sum_row(raw[raw.Variable == \"New case/s (confirmed)\"], total_col)\n",
    "    list_cases_upper = ([\"New Case/s (Suspected)\", \n",
    "                        \"New Case/s (Probable)\",\n",
    "                        \"New case/s (confirmed)\"])\n",
    "    new_cases_upper = sum_rows([raw[raw.Variable == row] for row in list_cases_upper], total_col)\n",
    "        \n",
    "    new_deaths_lower = sum_row(raw[raw.Variable == \"Newly reported deaths\"], total_col)\n",
    "    new_deaths_upper = new_deaths_lower\n",
    "    \n",
    "    return {'Country' : country, 'Date' : parse(date), 'NewCasesLower' : new_cases_lower, 'NewCasesUpper' : new_cases_upper, 'NewDeathsLower' : new_deaths_lower, 'NewDeathsUpper' : new_deaths_upper}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the files for the Sierra Leone does not contain data for the new deaths, we first extract the total deaths for each day, and we will process them later to get the new deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_sl(file):\n",
    "    country = 'sl'\n",
    "    date = file[:10]\n",
    "    raw = pd.read_csv(DATA_FOLDER + \"/ebola/\" + country + \"_data/\" + file).fillna(0)\n",
    "    total_col = \"National\"\n",
    "        \n",
    "    new_cases_lower = sum_row(raw[raw.variable == \"new_confirmed\"], total_col)\n",
    "    list_cases_upper = ([\"new_suspected\", \n",
    "                        \"new_probable\",\n",
    "                        \"new_confirmed\"])\n",
    "    new_cases_upper = sum_rows([raw[raw.variable == row] for row in list_cases_upper], total_col)\n",
    "    \n",
    "    list_death_upper = ([\"death_suspected\", \n",
    "                        \"death_probable\",\n",
    "                        \"death_confirmed\"])\n",
    "    total_death_upper = sum_rows([raw[raw.variable == row] for row in list_death_upper], total_col)\n",
    "    total_death_lower = sum_row(raw[raw.variable == \"death_confirmed\"], total_col)\n",
    "    \n",
    "    return {'Country' : country, 'Date' : parse(date), 'NewCasesLower' : new_cases_lower, 'NewCasesUpper' : new_cases_upper, 'TotalDeathLower' : total_death_lower, 'TotalDeathUpper' : total_death_upper}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_guinea = [get_row_guinea(file) for file in get_files(\"guinea\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_liberia = [get_row_liberia(file) for file in get_files(\"liberia\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now transform the data for the Sierra Leone :\n",
    "-we first create a new dictionary for which the keys are date, and the values are the previously extracted values from the .csv files.\n",
    "-then for each value in this dictionary, we try to get the value of the day before, and perform the difference to get the new deaths of this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows_sl_total_deaths = [get_row_sl(file) for file in get_files(\"sl\")]\n",
    "dic_sl_total_deaths = {}\n",
    "for row in rows_sl_total_deaths:\n",
    "    dic_sl_total_deaths[row['Date']] = row\n",
    "    \n",
    "rows_sl = []\n",
    "for date, entry in dic_sl_total_deaths.items():\n",
    "    date_before = date - datetime.timedelta(days=1)\n",
    "    if date_before in dic_sl_total_deaths:\n",
    "        \n",
    "        if entry['TotalDeathUpper'] != 0 and dic_sl_total_deaths[date_before]['TotalDeathUpper'] != 0 and entry['TotalDeathLower'] != 0 and dic_sl_total_deaths[date_before]['TotalDeathLower'] != 0: \n",
    "            copy = dict(entry)\n",
    "            del copy['TotalDeathUpper']\n",
    "            del copy['TotalDeathLower']\n",
    "            \n",
    "            copy['NewDeathsUpper'] = entry['TotalDeathUpper'] - dic_sl_total_deaths[date_before]['TotalDeathUpper']\n",
    "            copy['NewDeathsLower'] = entry['TotalDeathLower'] - dic_sl_total_deaths[date_before]['TotalDeathLower']\n",
    "\n",
    "            rows_sl.append(copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now insert the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_dataframe = pd.DataFrame(columns=['Country', 'Date', 'NewCasesLower', 'NewCasesUpper', 'NewDeathsLower', 'NewDeathsUpper'])\n",
    "for row in rows_sl, rows_guinea:\n",
    "    raw_dataframe = raw_dataframe.append(row, ignore_index = True)\n",
    "for row in rows_liberia:\n",
    "    if row['Date'].month != 12: #December data is erroneous\n",
    "        raw_dataframe = raw_dataframe.append(row, ignore_index = True)\n",
    "        \n",
    "raw_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = raw_dataframe.set_index(['Country', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe_no_day = raw_dataframe\n",
    "dataframe_no_day['Year'] = raw_dataframe['Date'].apply(lambda x: x.year)\n",
    "dataframe_no_day['Month'] = raw_dataframe['Date'].apply(lambda x: x.month)\n",
    "final_df = dataframe_no_day[['Country', 'Year', 'Month', 'NewCasesLower', 'NewCasesUpper', 'NewDeathsLower', 'NewDeathsUpper']].groupby(['Country', 'Year', 'Month']).mean()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, to have some final general idea for the data, we average the bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = final_df[['NewCasesLower', 'NewCasesUpper']].mean(axis=1)\n",
    "s2 = final_df[['NewDeathsLower', 'NewDeathsUpper']].mean(axis=1)\n",
    "final = pd.concat([s1, s2], axis=1)\n",
    "final.columns = ['NewCasesAverage', 'NewDeathsAverage']\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the first spreadsheet from the file's Sheet 1. Then we add a new column that is the same for all the data in this import, which corresponds to the barcode of the code.\n",
    "\n",
    "Then we rename the columns for more clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = pd.read_excel(DATA_FOLDER + '/microbiome/MID1.xls', sheetname='Sheet 1', header=None)\n",
    "mid.fillna('unknown', inplace=True)\n",
    "mid['BARCODE'] = 'MID1'\n",
    "mid.columns = ['Taxon', 'Count', 'BARCODE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat this operation for every other spreadsheet except the metadata. At each iteration we simply concatenate the data at the end of the previous data, this accumulating all the files' data into a single dataframe. We don't care about any index right now since we will use a random one later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    midi = pd.read_excel(DATA_FOLDER + '/microbiome/MID' + str(i) + '.xls', sheetname='Sheet 1', header=None)\n",
    "    midi.fillna('unknown', inplace=True)\n",
    "    midi['BARCODE'] = 'MID' + str(i)\n",
    "    midi.columns = ['Taxon', 'Count', 'BARCODE']\n",
    "    mid = pd.concat([mid, midi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we do a merge with the metadata. We join on the `BARCODE` column. This column will be the index of the metadata when we import it in this case. Finally we set the index for the three columns `BARCODE`, `GROUP` and `SAMPLE` which are all the columns of the metada and are unique.\n",
    "\n",
    "The only `NaN` value we found was the NA value on the metadata, which may indicate that there is no sample for the first group. We replaced it anyway by `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(DATA_FOLDER + '/microbiome/metadata.xls', sheetname='Sheet1', index_col=0)\n",
    "metadata.fillna('unknown', inplace=True)\n",
    "merged = pd.merge(mid, metadata, right_index=True, left_on='BARCODE')\n",
    "merged = merged.set_index(keys=['BARCODE', 'Taxon'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** We start by importing the data from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "import pandas as pd\n",
    "titanic = pd.read_excel(DATA_FOLDER + '/titanic.xls', sheetname='titanic')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can list the data types of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to the `object` fields, we can be a bit more precise. `name`, `sec`, `ticket`, `cabin`, `embarked`, `boat` and `home.dex` are all strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we call the `describe` method to list some statistics on the data. We thus obtain the range of all of the numeric fields of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can also note some ranges of other fields. For example, `sex` has only two possible values `female` and `male`. `embarked` can only be `S`, `C` and `Q`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better visual result, we decided to replace the travel classes, ports to more readable values. As we make  them categorical types, the performance stays the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['pclass'] = titanic['pclass'].apply(lambda x: (\"First\" if x == 1 else (\"Second\" if x == 2 else \"Third\")) + \" Class\")\n",
    "\n",
    "titanic['survived'] = titanic['survived'].apply(lambda x: \"Survived\" if x == 1 else \"Deceased\")\n",
    "\n",
    "titanic['embarked'] = titanic['embarked'].apply(lambda x: \"Cherbourg\" if x == 'C' else (\"Queenstown\" if x == 'Q' else \"Southampton\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we make categorical data as actually categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['pclass'] = titanic.pclass.astype('category')\n",
    "titanic['survived'] = titanic.survived.astype('category')\n",
    "titanic['sex'] = titanic.sex.astype('category')\n",
    "titanic['embarked'] = titanic.embarked.astype('category')\n",
    "titanic['cabin'] = titanic.cabin.astype('category')\n",
    "titanic['boat'] = titanic.boat.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** We plot the histogram of the travel class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.pclass.value_counts(sort=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the histogram of the three embark ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.embarked.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the histogram of the sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.sex.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we cut the ages data into decades and plot the histogram of the devades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(titanic.age, range(0,90,10)).value_counts(sort=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** We plot the cabin floor data as a pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.cabin.dropna().apply(lambda x : x[0]).value_counts(sort=False).plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Here, we plot the proportion of people that survived in the first class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic.pclass == \"First Class\"].survived.value_counts(sort=False).plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the proportion of people that survived in the second class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic.pclass == \"Second Class\"].survived.value_counts(sort=False).plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the proportion of people that survived in the third class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic.pclass == \"Third Class\"].survived.value_counts(sort=False).plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Here we add new columns that will help us to calculate proportions of survived people in the last part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.insert(0, 'alive', 0)\n",
    "titanic.insert(0, 'dead', 0)\n",
    "titanic.insert(0, 'ratio', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set these new columns to appropriate values. We essentialy separate the survived columns for easier summing later on. Finnaly we slice the data to take only the columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic['survived'] == \"Survived\", 'alive'] = 1\n",
    "titanic.loc[titanic['survived'] == \"Deceased\", 'dead'] = 1\n",
    "df = titanic[['pclass', 'sex', 'alive', 'dead', 'ratio']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the data by the sec and class of the passangers and we sum it. Then we have the sum of alive and dead people groupped as we wish and we can easily calculate the proportion of them that survived, which we plot as a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = df.groupby(['sex', 'pclass']).sum()\n",
    "(aggregated['alive'] / (aggregated['alive'] + aggregated['dead'])).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Next we insert a new column that will be the age category of each person. Since we wan't to split the people in two equal groups based on age, we compute the median age of passangers. We also drop the passengers with an unknown age value, to avoid bad results for the median computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.dropna(axis=0, subset=['age'], inplace=True)\n",
    "titanic.insert(0, 'age_category', 0)\n",
    "median = titanic['age'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set the correct category to people below or above the median age. The people that have the median age are grouped with the people below it. Next we set this column as a categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic['age'] > median, 'age_category'] = \"Age > \" + str(median)\n",
    "titanic.loc[titanic['age'] <= median, 'age_category'] = \"Age <= \" + str(median)\n",
    "titanic['age_category'] = titanic.age_category.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take the columns that are of interest to us and group by age category, sec and travel class. Then we sum over these groups, obtaining the people that lived and those that died which which we can compute the proportion and display it as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = titanic[['pclass', 'sex', 'age_category', 'alive', 'dead', 'ratio']]\n",
    "subagg = sub.groupby(['age_category', 'sex', 'pclass']).sum()\n",
    "subagg['ratio'] = (subagg['alive'] / (subagg['alive'] + subagg['dead']))\n",
    "only_ratio = subagg[['ratio']]\n",
    "only_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
