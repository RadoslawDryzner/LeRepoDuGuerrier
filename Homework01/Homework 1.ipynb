{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import everything we will need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define some helpful functions that will help us during the parsing of the data.\n",
    "- get_files: returns all the .csv files for a given country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_files(country):\n",
    "    path = DATA_FOLDER + \"/ebola/\" + country + \"_data/\"\n",
    "    return [f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sum_row: for a given row, returns the total value for the new cases / deaths. We first defined this function as the sum of all new cases / deaths in all provinces, but we discovered some strange data for some provinces, so we decided to only take into account the 'total' column\n",
    "- sum_rows: sum all the rows given in argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_row(row, total_col):\n",
    "    return float(row[total_col].values[0])\n",
    "\n",
    "def sum_rows(rows, total_col):\n",
    "    tot = 0\n",
    "    for row in rows:\n",
    "        tot += sum_row(row, total_col)\n",
    "    return tot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define for each country a function, which, for a given file, returns a dictionnary with the country, date, upper and lower bounds for the new cases, and upper and lower bounds for the new deaths.\n",
    "As we don't know if the new cases / deaths for the 'probable' and 'suspected' cases is reliable, we decided to create an upper bound with the sum of the 'confirmed', 'probable' and 'suspected' new cases / deaths, and a lower bound with only the 'confirmed' new cases / deaths.\n",
    "\n",
    "The structure of these functions are the same for each country, only the name of the descrption of the data changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_row_guinea(file):\n",
    "    country = 'guinea'\n",
    "    date = file[:10]\n",
    "    raw = pd.read_csv(DATA_FOLDER + \"/ebola/\" + country + \"_data/\" + file)\n",
    "    total_col = \"Totals\"\n",
    "    \n",
    "    new_cases_lower = sum_row(raw[raw.Description == \"New cases of confirmed\"], total_col)\n",
    "    new_cases_upper = sum_row(raw[raw.Description == \"Total new cases registered so far\"], total_col)\n",
    "        \n",
    "    new_deaths_lower = sum_row(raw[(raw.Description == \"New deaths registered today (confirmed)\") | (raw.Description == \"New deaths registered\")], total_col)\n",
    "    new_deaths_upper = sum_row(raw[(raw.Description == \"New deaths registered today\") | (raw.Description == \"New deaths registered\")], total_col)\n",
    "    \n",
    "    return {'Country' : country, 'Date' : parse(date), 'NewCasesLower' : new_cases_lower, 'NewCasesUpper' : new_cases_upper, 'NewDeathsLower' : new_deaths_lower, 'NewDeathsUpper' : new_deaths_upper}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_row_liberia(file):\n",
    "    country = 'liberia'\n",
    "    date = file[:10]\n",
    "    raw = pd.read_csv(DATA_FOLDER + \"/ebola/\" + country + \"_data/\" + file).fillna(0)\n",
    "    total_col = \"National\"\n",
    "    \n",
    "    new_cases_lower = sum_row(raw[raw.Variable == \"New case/s (confirmed)\"], total_col)\n",
    "    list_cases_upper = ([\"New Case/s (Suspected)\", \n",
    "                        \"New Case/s (Probable)\",\n",
    "                        \"New case/s (confirmed)\"])\n",
    "    new_cases_upper = sum_rows([raw[raw.Variable == row] for row in list_cases_upper], total_col)\n",
    "        \n",
    "    new_deaths_lower = sum_row(raw[raw.Variable == \"Newly reported deaths\"], total_col)\n",
    "    new_deaths_upper = new_deaths_lower\n",
    "    \n",
    "    return {'Country' : country, 'Date' : parse(date), 'NewCasesLower' : new_cases_lower, 'NewCasesUpper' : new_cases_upper, 'NewDeathsLower' : new_deaths_lower, 'NewDeathsUpper' : new_deaths_upper}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the files for the Sierra Leone does not contain data for the new deaths, we first extract the total deaths for each day, and we will process them later to get the new deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_sl(file):\n",
    "    country = 'sl'\n",
    "    date = file[:10]\n",
    "    raw = pd.read_csv(DATA_FOLDER + \"/ebola/\" + country + \"_data/\" + file).fillna(0)\n",
    "    total_col = \"National\"\n",
    "        \n",
    "    new_cases_lower = sum_row(raw[raw.variable == \"new_confirmed\"], total_col)\n",
    "    list_cases_upper = ([\"new_suspected\", \n",
    "                        \"new_probable\",\n",
    "                        \"new_confirmed\"])\n",
    "    new_cases_upper = sum_rows([raw[raw.variable == row] for row in list_cases_upper], total_col)\n",
    "    \n",
    "    list_death_upper = ([\"death_suspected\", \n",
    "                        \"death_probable\",\n",
    "                        \"death_confirmed\"])\n",
    "    total_death_upper = sum_rows([raw[raw.variable == row] for row in list_death_upper], total_col)\n",
    "    total_death_lower = sum_row(raw[raw.variable == \"death_confirmed\"], total_col)\n",
    "    \n",
    "    return {'Country' : country, 'Date' : parse(date), 'NewCasesLower' : new_cases_lower, 'NewCasesUpper' : new_cases_upper, 'TotalDeathLower' : total_death_lower, 'TotalDeathUpper' : total_death_upper}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_guinea = [get_row_guinea(file) for file in get_files(\"guinea\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_liberia = [get_row_liberia(file) for file in get_files(\"liberia\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now transform the data for the Sierra Leone :\n",
    "-we first create a new dictionary for which the keys are date, and the values are the previously extracted values from the .csv files.\n",
    "-then for each value in this dictionary, we try to get the value of the day before, and perform the difference to get the new deaths of this day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows_sl_total_deaths = [get_row_sl(file) for file in get_files(\"sl\")]\n",
    "dic_sl_total_deaths = {}\n",
    "for row in rows_sl_total_deaths:\n",
    "    dic_sl_total_deaths[row['Date']] = row\n",
    "    \n",
    "rows_sl = []\n",
    "for date, entry in dic_sl_total_deaths.items():\n",
    "    date_before = date - datetime.timedelta(days=1)\n",
    "    if date_before in dic_sl_total_deaths:\n",
    "        \n",
    "        if entry['TotalDeathUpper'] != 0 and dic_sl_total_deaths[date_before]['TotalDeathUpper'] != 0 and entry['TotalDeathLower'] != 0 and dic_sl_total_deaths[date_before]['TotalDeathLower'] != 0: \n",
    "            copy = dict(entry)\n",
    "            del copy['TotalDeathUpper']\n",
    "            del copy['TotalDeathLower']\n",
    "            \n",
    "            copy['NewDeathsUpper'] = entry['TotalDeathUpper'] - dic_sl_total_deaths[date_before]['TotalDeathUpper']\n",
    "            copy['NewDeathsLower'] = entry['TotalDeathLower'] - dic_sl_total_deaths[date_before]['TotalDeathLower']\n",
    "\n",
    "            rows_sl.append(copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now insert the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_dataframe = pd.DataFrame(columns=['Country', 'Date', 'NewCasesLower', 'NewCasesUpper', 'NewDeathsLower', 'NewDeathsUpper'])\n",
    "for row in rows_sl, rows_guinea:\n",
    "    raw_dataframe = raw_dataframe.append(row, ignore_index = True)\n",
    "for row in rows_liberia:\n",
    "    if row['Date'].month != 12: #December data is erroneous\n",
    "        raw_dataframe = raw_dataframe.append(row, ignore_index = True)\n",
    "        \n",
    "raw_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = raw_dataframe.set_index(['Country', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe_no_day = raw_dataframe\n",
    "dataframe_no_day['Year'] = raw_dataframe['Date'].apply(lambda x: x.year)\n",
    "dataframe_no_day['Month'] = raw_dataframe['Date'].apply(lambda x: x.month)\n",
    "final_df = dataframe_no_day[['Country', 'Year', 'Month', 'NewCasesLower', 'NewCasesUpper', 'NewDeathsLower', 'NewDeathsUpper']].groupby(['Country', 'Year', 'Month']).mean()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, to have some final general idea for the data, we average the bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = final_df[['NewCasesLower', 'NewCasesUpper']].mean(axis=1)\n",
    "s2 = final_df[['NewDeathsLower', 'NewDeathsUpper']].mean(axis=1)\n",
    "final = pd.concat([s1, s2], axis=1)\n",
    "final.columns = ['NewCasesAverage', 'NewDeathsAverage']\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the first spreadsheet from the file's Sheet 1. Then we add a new column that is the same for all the data in this import, which corresponds to the barcode of the code.\n",
    "\n",
    "Then we rename the columns for more clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = pd.read_excel(DATA_FOLDER + '/microbiome/MID1.xls', sheetname='Sheet 1', header=None)\n",
    "mid.fillna('unknown', inplace=True)\n",
    "mid['BARCODE'] = 'MID1'\n",
    "mid.columns = ['Taxon', 'Count', 'BARCODE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we repeat this operation for every other spreadsheet except the metadata. At each iteration we simply concatenate the data at the end of the previous data, this accumulating all the files' data into a single dataframe. We don't care about any index right now since we will use a random one later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 10):\n",
    "    midi = pd.read_excel(DATA_FOLDER + '/microbiome/MID' + str(i) + '.xls', sheetname='Sheet 1', header=None)\n",
    "    midi.fillna('unknown', inplace=True)\n",
    "    midi['BARCODE'] = 'MID' + str(i)\n",
    "    midi.columns = ['Taxon', 'Count', 'BARCODE']\n",
    "    mid = pd.concat([mid, midi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we do a merge with the metadata. We join on the `BARCODE` column. This column will be the index of the metadata when we import it in this case. Finally we set the index for the three columns `BARCODE`, `GROUP` and `SAMPLE` which are all the columns of the metada and are unique.\n",
    "\n",
    "The only `NaN` value we found was the NA value on the metadata, which may indicate that there is no sample for the first group. We replaced it anyway by `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(DATA_FOLDER + '/microbiome/metadata.xls', sheetname='Sheet1', index_col=0)\n",
    "metadata.fillna('unknown', inplace=True)\n",
    "merged = pd.merge(mid, metadata, right_index=True, left_on='BARCODE')\n",
    "merged = merged.set_index(keys=['BARCODE', 'Taxon'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
